# -*- coding: utf-8 -*-
"""Customer_Churn_Prediciton.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1soANOj88A8Vokh-6o9j6j0lIHEQmy8yw
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

df = pd.read_csv('Churn_Modelling.csv')
print(df.head())

print(f"Dataset Shape: {df.shape}")
print(df.info())

print(df.isnull().sum())

sns.countplot(x='Exited', data=df)
plt.title('Distribution of Exited (Target Variable)')
plt.xlabel('Exited')
plt.ylabel('Count')
plt.show()

sns.histplot(df['Age'], bins=30, kde=True)
plt.title('Age Distribution')
plt.show()

sns.boxplot(x='Exited', y='CreditScore', data=df)
plt.title('Credit Score by Exited')
plt.show()

sns.countplot(x='Geography', hue='Exited', data=df)
plt.title('Churn by Geography')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
numeric_df = df.select_dtypes(include=['int64', 'float64'])
corr_matrix = numeric_df.corr()
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Correlation Heatmap (Numeric Features Only)')
plt.show()

categorical_cols = ['Geography', 'Gender']
le = LabelEncoder()
df['Gender'] = le.fit_transform(df['Gender'])
df = pd.get_dummies(df, columns=['Geography'], drop_first=True)
print(df.head())

scale_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']
scaler = StandardScaler()
df[scale_cols] = scaler.fit_transform(df[scale_cols])
print(df.head())

df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)
X = df.drop('Exited', axis=1)
y = df['Exited']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f'Training set size: {X_train.shape}')
print(f'Testing set size: {X_test.shape}')

"""Logistic Regression"""

log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
y_pred_log = log_reg.predict(X_test)
print("Logistic Regression Classification Report:")
print(classification_report(y_test, y_pred_log))
print("Logistic Regression ROC AUC Score:", roc_auc_score(y_test, log_reg.predict_proba(X_test)[:,1]))

"""Random Foprest Classification"""

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
print("Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))
print("Random Forest ROC AUC Score:", roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]))

"""Gradient Boosting Classification"""

gb = GradientBoostingClassifier(random_state=42)
gb.fit(X_train, y_train)
y_pred_gb = gb.predict(X_test)
print("Gradient Boosting Classification Report:")
print(classification_report(y_test, y_pred_gb))
print("Gradient Boosting ROC AUC Score:", roc_auc_score(y_test, gb.predict_proba(X_test)[:,1]))

models = {
    'Logistic Regression': log_reg,
    'Random Forest': rf,
    'Gradient Boosting': gb
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])
    print(f"{name} ROC AUC Score: {auc:.4f}")

from sklearn.metrics import confusion_matrix

for name, model in models.items():
    cm = confusion_matrix(y_test, model.predict(X_test))
    sns.heatmap(cm, annot=True, fmt='d')
    plt.title(f'{name} Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

for name, model in models.items():
    y_proba = model.predict_proba(X_test)[:,1]
    fpr, tpr, thresholds = roc_curve(y_test, y_proba)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc_score(y_test, y_proba):.2f})')

plt.plot([0,1], [0,1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

"""Hyperparameter Tuning"""

param_grid_rf = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}
grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf,
                       cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)
grid_rf.fit(X_train, y_train)
print("Best parameters for Random Forest:", grid_rf.best_params_)
print("Best ROC AUC Score:", grid_rf.best_score_)

param_grid_gb = {
    'n_estimators': [100, 200],
    'learning_rate': [0.01, 0.1],
    'max_depth': [3, 5],
    'subsample': [0.8, 1.0]
}
grid_gb = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid_gb,
                       cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)
grid_gb.fit(X_train, y_train)
print("Best parameters for Gradient Boosting:", grid_gb.best_params_)
print("Best ROC AUC Score:", grid_gb.best_score_)

from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix
best_gb = grid_gb.best_estimator_
y_pred = best_gb.predict(X_test)
y_proba = best_gb.predict_proba(X_test)[:, 1]
print("Gradient Boosting Classification Report:")
print(classification_report(y_test, y_pred))
roc_auc = roc_auc_score(y_test, y_proba)
print(f"Gradient Boosting ROC AUC Score: {roc_auc:.4f}")
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Gradient Boosting Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
plt.plot(fpr, tpr, label=f'Gradient Boosting (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Gradient Boosting')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
feature_importances = pd.Series(best_gb.feature_importances_, index=X.columns).sort_values(ascending=False)
plt.figure(figsize=(10, 8))
sns.barplot(x=feature_importances, y=feature_importances.index)
plt.title('Feature Importances - Gradient Boosting')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.tight_layout()
plt.show()

pip install shap

import shap
shap.initjs()
explainer = shap.TreeExplainer(best_gb)
shap_values = explainer.shap_values(X_test)
shap.summary_plot(shap_values, X_test, plot_type="bar")
shap.summary_plot(shap_values, X_test)

import sklearn
print(sklearn.__version__)

from sklearn.inspection import PartialDependenceDisplay
import matplotlib.pyplot as plt
top_features = feature_importances.index[:3]
PartialDependenceDisplay.from_estimator(
    best_gb,
    X_test,
    features=top_features,
    grid_resolution=20,
    kind='average'  # You can also specify 'individual' for individual PDPs
)
plt.tight_layout()
plt.show()

import joblib
joblib.dump(best_gb, 'gradient_boosting_churn_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
feature_columns = X.columns.tolist()
joblib.dump(feature_columns, 'features.pkl')

import json
with open('feature_columns.json', 'w') as f:
    json.dump(feature_columns, f)

import json
with open('feature_columns.json', 'r') as f:
    feature_columns = json.load(f)